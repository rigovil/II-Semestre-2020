Multihilos
procesador que es capaz de manejar varios hilos. Debe tener toda la circuitería necesaria para manejar un PC, registros, etc. para cada hilo. Un procesador para ser superescalar debe tener varios puntos de emisión (varios ID's). Desperdicio vertical: ciclos en donde no se emite ninguna instrucción. Desperdicio horizontal: cuando no se emiten el total de instrucciones que se pueden emitir a la vez. 

Multihilo de grano grueso: se empiezan a emitir instrucciones del hilo x, y cuando este hilo tiene un retraso muy grande (por un fallo de caché por ejemplo) entonces se cambia de contexto de manera interna (en el procesador), este contexto es el PC, valor de registros, etc. de un programa y se copian en memoria en una parte definida por el S.O y sube el contexto del siguiente programa al que se le va a dar el CPU.

Multihilo de grano fino: en cada ciclo de reloj se cambia de hilo en los cuales se ejecutan instrucciones. En un ciclo se emiten instrucciones únicamente de un hilo, es necesario el procesador saber a qué hilo pertenecen las instrucciones. Los hilos pueden ser de un mismo proceso o no.

Multihilos simultáneos: así trabajan actualmente los procesadores, en un ciclo de reloj es posible emitir instrucciones de hilos diferentes.

Jerarquías de Memoria
la clasificación de las jerarquías de memoria se basa en 4 aspectos, cuando se pide un dato a una caché, se le debe indicar el número de bloque (grupo de palabras) y el número de palabra (grupo de bytes).

	I. Colocación del Bloque (asignación): existen 3 estrategias diferentes para la asignación de bloques. Se divide la caché por bloques, con 4 campos para las 4 palabras de ese bloque, seguido de un TAG, usualmente el TAG es la dirección física en memoria donde comienza el bloque o el número de bloque; y otro campo que indica el estado del bloque (inválido, modificado, compartido). La primera estrategia es MAPEO DIRECTO, es la que permite dividr la etapa de MEM en 3, porque hay un único lugar donde se puede poner el bloque. Para saber dónde va el bloque se hace la operación #bloque % #bloques que hay en caché. Es la que más fallos de caché produce porque muchos bloques en memoria pueden ir en una sola posición en la caché. La siguiente estrategia es COMPLETAMENTE ASOCIATIVA, es la más cara y compleja pero la que produce menos fallos de caché y más lenta que mapeo directo, cualquier bloque de memoria puede ir en cualquier parte de la caché, posee varias estrategias de reemplazo (aleatorio, caerle encima al bloque más viejo, caerle encima al bloque menos usado recientemente (la mejor)). La siguiente estrategia es ASOCIATIVA POR CONJUNTOS, los bloques de la caché se reparten en conjuntos, depende de cuántos bloques tenga un conjunto se dice que es asociativa por conjuntos de n vías. Y para asignar un bloque de memoria a la caché se hace la operación #bloque % #conjuntos en caché, y dentro de ese conjunto se asigna como si fuera completamente asociativa siguiendo la estrategia de reemplazo definida.
	
	II. Identificación del Bloque: depende de la estrategia para la asignación del bloque. Si es mapeo directo se hace la operación del número de bloque en memoria para buscarla en la caché. Si es completamente asociativa se busca en todas las posiciones si está el bloque, pero se permite hacer en paralelo. Si es asociativa por conjuntos, se hace el cálculo del número de conjunto al que pertenecería el bloque y ahí dentro se usa la misma técnica anterior que permite buscar en paralelo todas las posiciones de ese conjunto. En orden de más lento a menos lento y de menor tasa de fallos a mayor tasa de fallos: Complet. asoc > Asoc. conj. > M.D.
	
	III. Reemplazo de Bloques: si se va a subir un bloque a la caché. Si es mapeo directo la posición está ya definida. Para las otras dos estrategias existen varias formas de reemplazo: aleatorio, LRU (menos usado recienteme, es la mejor y más cara), FIFO.
	
	IV. Estrategia de Escritura (store): existen dos casos, si el bloque sí está en caché, en cuyo caso existen dos estrategias: la primera es WRITE THROUGH, que lo que hace es modificar la palabra en el bloque de la caché y además lo modifica en el siguiente nivel en la jerarquía de memoria (es lento). La segunda estrategia es WRITE BACK, que lo que hace es modificar solamente la caché y se cambia el estado del bloque a "modificado". Si luego alguien busca ese bloque, se copia a memoria y se le manda a la caché que lo necesita y cambia el estado a "compartido" o si un bloque nuevo va a ocupar el campo de ese bloque modificado en la caché (en mapeo directo) entonces también se manda a cambiar a memoria antes de que le caigan encima. Si el bloque no está en la caché, también existen dos estrategias: la primera es NO- WRITE ALLOCATE (no suba el bloque), lo que hace es mandarlo a cambiar al siguiente nivel. La segunda estrategia es WRITE ALLOCATE, se sube el bloque en cuestión a la caché desde alguien más abajo en la jerarquía y la palabra que se va a modificar de ese bloque le cae encima pero en la caché pero antes se procede de manera que depende de la estrategia escogida para cuando hay aciertos.
